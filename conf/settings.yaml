VENUE: '{{VENUE}}'
DATASET_BUCKET: '{{ DATASET_BUCKET }}'
PGE_SIMULATION_MODE: !!bool true
CRID: '{{ CRID }}'
RELEASE_VERSION: '{{ RELEASE_VERSION }}'

GRQ_ES_ENGINE: opensearch

# for PST (CalVal products)
#DSWX_HLS_COLLECTION_NAME: "OPERA_L3_DSWX-HLS_PROVISIONAL_V0"
#DSWX_HLS_PRODUCT_VERSION: "0.0"

# uncomment out for OPS in R1
DSWX_HLS_COLLECTION_NAME: "OPERA_L3_DSWX-HLS_V1"
DSWX_HLS_PRODUCT_VERSION: "1.0"

# CSLC & RTC in R2
CSLC_COLLECTION_NAME: "OPERA_L2_CSLC-S1_V1"
RTC_COLLECTION_NAME: "OPERA_L2_RTC-S1_V1"
CSLC_STATIC_COLLECTION_NAME: "OPERA_L2_CSLC-S1-STATIC_V1"
RTC_STATIC_COLLECTION_NAME: "OPERA_L2_RTC-S1-STATIC_V1"
CSLC_S1_PRODUCT_VERSION: "1.1"
RTC_S1_PRODUCT_VERSION: "1.0"
CSLC_S1_STATIC_PRODUCT_VERSION: "1.0"
RTC_S1_STATIC_PRODUCT_VERSION: "1.0"

# DSWx-S1 & DISP-S1 in R3
DSWX_S1_COLLECTION_NAME: "OPERA_L3_DSWX-S1_V1"
DSWX_S1_PRODUCT_VERSION: "1.0"
DISP_S1_COLLECTION_NAME: "OPERA_L3_DISP-S1_V1"
DISP_S1_PRODUCT_VERSION: "1.0"
DISP_S1_STATIC_COLLECTION_NAME: "OPERA_L3_DISP-S1-STATIC_PROVISIONAL_V0"
DISP_S1_STATIC_PRODUCT_VERSION: "1.0"

# DSWx-NI in R4
DSWX_NI_COLLECTION_NAME: "OPERA_L3_DSWX-NI_PROVISIONAL_V0"
DSWX_NI_PRODUCT_VERSION: "0.1"

# DIST-S1 in R6
DIST_S1_COLLECTION_NAME: "OPERA_L3_DIST-S1_PROVISIONAL_V0"
DIST_S1_PRODUCT_VERSION: "0.1"

# TROPO in R3.2
TROPO_COLLECTION_NAME: "OPERA_L4_TROPO-ZENITH_PROVISIONAL_V0"
TROPO_PRODUCT_VERSION: "0.1"

# DAAC S3 download credential URLs
USE_DAAC_S3_CREDENTIALS: !!bool true
DAAC_S3_CRED_URLS:
  HLS_DOWNLOAD: https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials
  SLC_DOWNLOAD: https://sentinel1.asf.alaska.edu/s3credentials
  RTC_DOWNLOAD: https://cumulus.asf.alaska.edu/s3credentials
  CSLC_DOWNLOAD: https://cumulus.asf.alaska.edu/s3credentials

# The minimum coverage, defined as the percent of bursts in a bursts set, required to run DSWx_S1
#  Must be an integer in the closed interval [0, 100] or null (~).
#  Cannot be set together with DSWX_S1_MINIMUM_NUMBER_OF_BURSTS_REQUIRED.
DSWX_S1_COVERAGE_TARGET: ~
# The minimum coverage, defined as the number of bursts in a bursts set, required to run DSWx_S1
#  Must be a non-negative integer or null (~).
#  Cannot be set together with DSWX_S1_COVERAGE_TARGET.
DSWX_S1_MINIMUM_NUMBER_OF_BURSTS_REQUIRED: 4
# Force DSWx-S1 processing of pending burst sets after X minutes, rather than waiting for additional data
DSWX_S1_COLLECTION_GRACE_PERIOD_MINUTES: 210
MGRS_TILE_COLLECTION_DB_S3PATH: "s3://opera-ancillaries/mgrs_tiles/dswx_s1/MGRS_tile_collection_v0.3.sqlite"

# The minimum coverage, defined as the percent of bursts in a bursts set, required to run DISP_S1
#  Must be a number in the closed interval [0, 99].
DISP_S1_COVERAGE_TARGET: 99

# Force DISP-S1 processing of pending burst sets after X minutes, rather than waiting for additional data
# This can be over-ridden by argument into daac_data_subsriber.py
DEFAULT_DISP_S1_QUERY_GRACE_PERIOD_MINUTES: 210

# The k-multiple by which the CSLC granules are queried from CMR at a time for DISP-S1 processing.
# If k=4 and this multiple is 2 then the CSLC granules will be queried by 8 acquisition-cycles at a time, which would be
# 8 * 12  = 96 days. We can tune this number to minimize CMR queries without adding undue load on CMR.
DISP_S1_K_FETCH_MULTIPLE: 2

# This file contains mapping of frame_id to burst_id and all its sensing times based on real CMR data
DISP_S1_BURST_DB_S3PATH: "s3://opera-ancillaries/disp_frames/disp_s1_consistent_burst_db/opera-disp-s1-consistent-burst-ids-2025-02-13-2016-07-01_to_2024-12-31.json"

# This file contains list of blackout date ranges for DISP-S1 processing on a per-frame basis
DISP_S1_BLACKOUT_DATES_S3PATH: "s3://opera-ancillaries/disp_frames/disp_s1_blackout_dates/sample_disp_s1_blackout.json"

# This file contains geo boundaries of all DISP-S1 frames
DISP_S1_FRAME_GEO_SIMPLE: "s3://opera-ancillaries/disp_frames/disp_s1_frame_geo_simple/frame-geometries-simple.geojson"

# Force DIST-S1 processing of pending burst sets after X minutes, rather than waiting for additional data
# This can be over-ridden by argument into daac_data_subsriber.py
DEFAULT_DIST_S1_QUERY_GRACE_PERIOD_MINUTES: 210

# Location of the burst lookup table for DIST-S1 processing
DIST_S1_BURST_DB_S3PATH: "s3://opera-ancillaries/dist_s1/mgrs_burst_lookup_table-2025-02-19.parquet"

# Shortname filtering on input product types. RegEx strings ('.' == any single character)
SHORTNAME_FILTERS:
  HLSL30:
#   - L.07 # Landsat-7
    - L.08 # Landsat-8
#   - L.09 # Landsat-9
  HLSS30:
#   - S1 # Sentinel-1
    - S2A # Sentinel-2A
    - S2B # Sentinel-2B
    - S2C # Sentinel-2C
#    - S2D # Sentinel-2D

GEOJSON_BUCKET: "opera-ancillaries"

# Base API urls and login endpoints for the different DAAC environments.
DAAC_ENVIRONMENTS:
  OPS:
    BASE_URL: cmr.earthdata.nasa.gov
    EARTHDATA_LOGIN: urs.earthdata.nasa.gov

  UAT:
    BASE_URL: cmr.uat.earthdata.nasa.gov
    EARTHDATA_LOGIN: uat.urs.earthdata.nasa.gov

# Settings to set the latency period for various jobs
NOMINAL_LATENCY:
    # Latency period in minutes. Expiration time is calculated from when the LDF is being processed.
#   RRST_EVALUATOR: 60

URGENT_RESPONSE_LATENCY:
    # Latency period in minutes. Expiration time is calculated from when the LDF is being processed.
#    RRST_EVALUATOR: 60


# This area is intended to be used to set any PGE configurable settings that an operator can change
# during production.

CSLC_S1:
  # Amount of margin in km to apply to staged ancillaries (DEM)
  ANCILLARY_MARGIN: 100
  # Product specification version for baseline products
  PRODUCT_SPEC_VER: 0.1.7

CSLC_S1_STATIC:
  # Amount of margin in km to apply to staged ancillaries (DEM)
  ANCILLARY_MARGIN: 100
  # Validity start date used to tag static layer products
  DATA_VALIDITY_START_DATE: 20140403
  # Product specification version for static layer products
  PRODUCT_SPEC_VER: 0.1.2

DSWX_HLS:
  # Toggle ancillary overlap coverage check during processing
  CHECK_ANCILLARY_INPUTS_COVERAGE: !!bool true
  # Toggle application of ocean/shoreline masking during processing
  APPLY_OCEAN_MASKING: !!bool false
  # Amount of margin in km to apply to staged ancillaries (DEM/Worldcover)
  ANCILLARY_MARGIN: 200

RTC_S1:
  # Amount of margin in km to apply to staged ancillaries (DEM)
  ANCILLARY_MARGIN: 200
  # Estimated geometric accuracy values needed for CEOS compliance
  ESTIMATED_GEOMETRIC_ACCURACY:
    BIAS_X: -0.72
    BIAS_Y: -0.67
    STDDEV_X: 0.70
    STDDEV_Y: 0.62

RTC_S1_STATIC:
  # Validity start date used to tag static layer products
  DATA_VALIDITY_START_DATE: 20140403
  # Amount of margin in km to apply to staged ancillaries (DEM)
  ANCILLARY_MARGIN: 200
  # Estimated geometric accuracy values needed for CEOS compliance
  ESTIMATED_GEOMETRIC_ACCURACY:
    BIAS_X: -0.72
    BIAS_Y: -0.67
    STDDEV_X: 0.70
    STDDEV_Y: 0.62

DSWX_S1:
  # Amount of margin in km to apply to staged ancillaries (DEM/Worldcover)
  ANCILLARY_MARGIN: 50

DISP_S1:
  # Amount of margin in km to apply to staged ancillaries (DEM)
  ANCILLARY_MARGIN: 50
  # Number of threads to allocate to the "threads_per_worker" field of the DISP-S1 RunConfig
  NUM_THREADS: 8
  # Used to calculate the "n_parallel_bursts" field of the DISP-S1 RunConfig
  # available_cpu_cores * FACTOR + CONSTANT
  NUM_WORKERS:
    FACTOR: 0.25
    CONSTANT: 1
  # S3 path to the frame-to-burst database JSON file to download for all DISP-S1 jobs
  FRAME_TO_BURST_JSON: "s3://opera-ancillaries/disp_frames/disp-s1/0.5.7/opera-s1-disp-0.9.0-frame-to-burst.json"
  # S3 path to the reference date database JSON file to download for all DISP-S1 jobs
  REFERENCE_DATE_DATABASE_JSON: "s3://opera-ancillaries/disp_frames/disp_s1_frame_reference_dates/opera-disp-s1-reference-dates-2025-02-13.json"
  # S3 path to the algorithm parameters override JSON file to download for all DISP-S1 jobs
  ALGORITHM_PARAMETERS_OVERRIDES_JSON: "s3://opera-ancillaries/algorithm_parameters/disp_s1/0.5.7/opera-disp-s1-algorithm-parameters-overrides-2025-02-21.json"

DISP_S1_STATIC:
  # Amount of margin in km to apply to staged ancillaries (DEM)
  ANCILLARY_MARGIN: 50
  # Number of threads to allocate to the "threads_per_worker" field of the DISP-S1 RunConfig
  NUM_THREADS: 8
  # Used to calculate the "n_parallel_bursts" field of the DISP-S1 RunConfig
  # available_cpu_cores * FACTOR + CONSTANT
  NUM_WORKERS:
    FACTOR: 0.25
    CONSTANT: 1
  # S3 path to the frame-to-burst database JSON file to download for all DISP-S1 jobs
  FRAME_TO_BURST_JSON: "s3://opera-ancillaries/disp_frames/disp-s1/0.5.7/opera-s1-disp-0.9.0-frame-to-burst.json"

DSWX_NI:
  # Amount of margin in km to apply to staged ancillaries (DEM/Worldcover)
  ANCILLARY_MARGIN: 50

DIST_S1:
  # Amount of margin in km to apply to staged ancillaries (Worldcover)
  ANCILLARY_MARGIN: 50

  DESIRED_LOOKBACKS: 3

  WORKERS:
    N_DESPECKLE: 16
    N_NORM_PARAMS: 1  # This doesn't seem to work as expected. Computes 2 bursts at a time but takes twice as long per
                      # burst, while eating up double the memory. Recommend keeping this at 1 for now until ADT can
                      # reassess

TROPO:
  # Number of workers to allocate to the "n_workers" field of the TROPO RunConfig
  NUM_WORKERS: 4
  # Number of threads to allocate to the "threads_per_worker" field of the TROPO RunConfig
  NUM_THREADS: 2
  # Maximum memory in MB to allocate to the "max_memory" field of the TROPO RunConfig
  MAX_MEMORY: 8GB


# End PGE Configuration section

PRODUCT_TYPES:
    Observation_Accountability_Report:
        Pattern: !!python/regexp '(?P<id>oad_(?P<ContentType>\w+)_(?P<ValidityStartDateTime>\d{4}-\d{3}T\d{2}:\d{2}:\d{2})_(?P<ValidityEndDateTime>\d{4}-\d{3}T\d{2}:\d{2}:\d{2})\.(xml|json))$'
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            Date_Time_Patterns: ['%Y-%jT%H:%M:%S']
        Strip_File_Extension: !!bool true
        Dataset_Keys:
            starttime: ValidityStartDateTime
            endtime: ValidityEndDateTime

    L1_S1_SLC:
        # Pattern for parsing SAFE archives containing SLC burst data from Sentinel-1, such as:
        # S1A_IW_SLC__1SDV_20220501T015035_20220501T015102_043011_0522A4_42CC.zip
        # This pattern groups the metadata information in the filename using named groups.
        #
        # See naming convention documentation (https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/naming-conventions)
        #
        Pattern: !!python/regexp '(?P<mission_id>S1A|S1B|S1C)_(?P<beam_mode>IW)_(?P<product_type>SLC)(?P<resolution>_)_(?P<level>1)(?P<class>S)(?P<pol>SH|SV|DH|DV)_(?P<start_ts>(?P<start_year>\d{4})(?P<start_month>\d{2})(?P<start_day>\d{2})T(?P<start_hour>\d{2})(?P<start_minute>\d{2})(?P<start_second>\d{2}))_(?P<stop_ts>(?P<stop_year>\d{4})(?P<stop_month>\d{2})(?P<stop_day>\d{2})T(?P<stop_hour>\d{2})(?P<stop_minute>\d{2})(?P<stop_second>\d{2}))_(?P<orbit_num>\d{6})_(?P<data_take_id>[0-9A-F]{6})_(?P<product_id>[0-9A-F]{4})[.](?P<format>zip)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            Date_Time_Patterns: ['%Y%m%dT%H%M%S']
            Date_Time_Keys: ['start_ts', 'stop_ts']
        Dataset_Keys: {}

    L1_S1_ORB:
        # Pattern for parsing Orbit files, both Precise (POE) and Restituted (RES) files
        # containing the orbit ephemerides data for Sentinel-1 A/B, such as:
        # S1A_OPER_AUX_POEORB_OPOD_20220521T081912_V20220430T225942_20220502T005942.EOF
        # This pattern groups the metadata information in the filename using named groups.
        #
        # See naming convention documentation (https://sentinel.esa.int/documents/247904/351187/Copernicus_Sentinels_POD_Service_File_Format_Specification)
        #
        Pattern: !!python/regexp '(?P<mission_id>S1A|S1B|S1C)_(?P<file_class>OPER)_(?P<file_type>(?P<category>AUX)_(?P<semantic_desc>POEORB|RESORB))_(?P<instance_id>(?P<site>OPOD)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2}))_V(?P<valid_start_ts>(?P<valid_start_year>\d{4})(?P<valid_start_month>\d{2})(?P<valid_start_day>\d{2})T(?P<valid_start_hour>\d{2})(?P<valid_start_minute>\d{2})(?P<valid_start_second>\d{2}))_(?P<valid_stop_ts>(?P<valid_stop_year>\d{4})(?P<valid_stop_month>\d{2})(?P<valid_stop_day>\d{2})T(?P<valid_stop_hour>\d{2})(?P<valid_stop_minute>\d{2})(?P<valid_stop_second>\d{2})))[.](?P<format>EOF)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            Date_Time_Patterns: ['%Y%m%dT%H%M%S']
            Date_Time_Keys: ['creation_ts', 'valid_start_ts', 'valid_stop_ts']
        Dataset_Keys: {}

    L2_HLS_L30:
        # Pattern for parsing filenames such as "HLS.L30.T22VEQ.2021248T143156.v2.0.Fmask.tif".
        # This pattern groups the metadata information in the filename using named groups.
        #
        # See naming convention documentation (https://lpdaac.usgs.gov/data/get-started-data/collection-overview/missions/harmonized-landsat-sentinel-2-hls-overview/#hls-naming-conventions)
        #
        # Note: POSIX character class "[[:alnum:]]" is not supported in python's re, and so has been replaced with "[^\W_]" here.
        Pattern: !!python/regexp '(?P<product_shortname>HLS[.]L30)[.](?P<tile_id>T[^\W_]{5})[.](?P<acquisition_ts>(?P<year>\d{4})(?P<day_of_year>\d{3})T(?P<hour>\d{2})(?P<minute>\d{2})(?P<second>\d{2}))[.](?P<collection_version>v\d+[.]\d+)[.](?P<band_or_qa>[^\W_]+)[.](?P<format>tif)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            # Custom Pattern for dates like "<year><day number of year>T<hour><minute><second>"
            # For example, "2021248T143156":
            #   year: 2021
            #   day number of year: 248
            #   hour (24hr): 14
            #   minute: 31
            #   second: 56
            Date_Time_Patterns: ['%Y%jT%H%M%S']

            # Specify the metadata key to convert to a start and end time for the dataset times
            Date_Time_Keys: ['acquisition_ts']
            # Specify the metadata key to use as the dataset version.
            #  Note: this affects the data product index name
            Dataset_Version_Key: 'collection_version'
        Dataset_Keys: {}

    L2_HLS_S30:
        # Pattern for parsing filenames such as "HLS.S30.T15SXR.2021250T163901.v2.0.Fmask.tif".
        # This pattern groups the metadata information in the filename using named groups.
        #
        # See naming convention documentation (https://lpdaac.usgs.gov/data/get-started-data/collection-overview/missions/harmonized-landsat-sentinel-2-hls-overview/#hls-naming-conventions)
        #
        # Note: POSIX character class "[[:alnum:]]" is not supported in python's re, and so has been replaced with "[^\W_]" here.
        Pattern: !!python/regexp '(?P<product_shortname>HLS[.]S30)[.](?P<tile_id>T[^\W_]{5})[.](?P<acquisition_ts>(?P<year>\d{4})(?P<day_of_year>\d{3})T(?P<hour>\d{2})(?P<minute>\d{2})(?P<second>\d{2}))[.](?P<collection_version>v\d+[.]\d+)[.](?P<band_or_qa>[^\W_]+)[.](?P<format>tif)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            # Custom Pattern for dates like "<year><day number of year>T<hour><minute><second>"
            # For example, "2021248T143156":
            #   year: 2021
            #   day number of year: 248
            #   hour (24hr): 14
            #   minute: 31
            #   second: 56
            Date_Time_Patterns: ['%Y%jT%H%M%S']

            # Specify the metadata key to convert to a start and end time for the dataset times
            Date_Time_Keys: ['acquisition_ts']
            # Specify the metadata key to use as the dataset version.
            #  Note: this affects the data product index name
            Dataset_Version_Key: 'collection_version'
        Dataset_Keys: {}

    L2_CSLC_S1:
        # Pattern for parsing output L2_CSLC-S1 product filenames, such as:
        # OPERA_L2_CSLC-S1_T064-135518-IW1_20220501T015035Z_20230807T212944Z_S1A_VV_v1.0.h5
        # This pattern groups the metadata information in the filename using named groups.
        Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L2)_(?P<product_type>CSLC)-(?P<source>S1)_(?P<burst_id>\w{4}-\w{6}-\w{3})_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<sensor>S1A|S1B|S1C)_(?P<pol>VV|VH|HH|HV|VV\+VH|HH\+HV)_(?P<product_version>v\d+[.]\d+))(_BROWSE)?[.](?P<ext>tif|tiff|h5|png|iso\.xml)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            Date_Time_Patterns: ['%Y%m%dT%H%M%SZ']
            Date_Time_Keys: ['acquisition_ts', 'creation_ts']
            # Specify the metadata key to use as the dataset version.
            #  Note: this affects the data product index name
            Dataset_Version_Key: 'product_version'
        Dataset_Keys: {}

    L2_CSLC_S1_STATIC:
      # Pattern for parsing output L2_CSLC-S1 static layer product filenames, such as:
      # OPERA_L2_CSLC-S1-STATIC_T064-135524-IW2_20140101_S1A_v1.0.h5
      # This pattern groups the metadata information in the filename using named groups.
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L2)_(?P<product_type>CSLC)-(?P<source>S1)-STATIC_(?P<burst_id>\w{4}-\w{6}-\w{3})_(?P<validity_ts>(?P<validity_year>\d{4})(?P<validity_month>\d{2})(?P<validity_day>\d{2}))_(?P<sensor>S1A|S1B|S1C)_(?P<product_version>v\d+[.]\d+))[.](?P<ext>h5|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        Date_Time_Patterns: [ '%Y%m%d' ]
        Date_Time_Keys: [ 'validity_ts' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L2_RTC_S1:
        # Pattern for parsing output L2_RTC-S1 product filenames, such as:
        # OPERA_L2_RTC-S1_T069-147174-IW3_20180504T104521Z_20230804T203850Z_S1B_30_v1.0.h5
        # OPERA_L2_RTC-S1_T069-147174-IW3_20180504T104521Z_20230804T203850Z_S1B_30_v1.0_VV.tif
        # OPERA_L2_RTC-S1_T069-147174-IW3_20180504T104521Z_20230804T203850Z_S1B_30_v1.0_mask.tif
        # OPERA_L2_RTC-S1_T069-147175-IW1_20180504T104522Z_20230804T203850Z_S1B_30_v1.0_BROWSE.png
        # This pattern groups the metadata information in the filename using named groups.
        Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L2)_(?P<product_type>RTC)-(?P<source>S1)_(?P<burst_id>\w{4}-\w{6}-\w{3})_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<sensor>S1A|S1B|S1C)_(?P<spacing>30)_(?P<product_version>v\d+[.]\d+))(_(?P<pol>VV|VH|HH|HV|VV\+VH|HH\+HV)|_BROWSE|_mask)?[.](?P<ext>tif|tiff|h5|png|iso\.xml)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
          Date_Time_Patterns: ['%Y%m%dT%H%M%SZ']
          Date_Time_Keys: ['acquisition_ts', 'creation_ts']
          # Specify the metadata key to use as the dataset version.
          #  Note: this affects the data product index name
          Dataset_Version_Key: 'product_version'
        Dataset_Keys: {}

    L2_RTC_S1_STATIC:
      # Pattern for parsing output L2_RTC-S1 static layer product filenames, such as:
      # OPERA_L2_RTC-S1-STATIC_T069-147178-IW3_20140101_S1B_30_v1.0.h5
      # OPERA_L2_RTC-S1-STATIC_T069-147178-IW3_20140101_S1B_30_v1.0_incidence_angle.tif
      # OPERA_L2_RTC-S1-STATIC_T069-147178-IW3_20140101_S1B_30_v1.0_number_of_looks.tif
      # This pattern groups the metadata information in the filename using named groups.
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L2)_(?P<product_type>RTC)-(?P<source>S1)-STATIC_(?P<burst_id>\w{4}-\w{6}-\w{3})_(?P<validity_ts>(?P<validity_year>\d{4})(?P<validity_month>\d{2})(?P<validity_day>\d{2}))_(?P<sensor>S1A|S1B|S1C)_(?P<spacing>30)_(?P<product_version>v\d+[.]\d+))(_BROWSE|_(?P<static_layer_name>incidence_angle|mask|local_incidence_angle|number_of_looks|rtc_anf_gamma0_to_beta0|rtc_anf_gamma0_to_sigma0))?[.](?P<ext>tif|tiff|h5|png|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        Date_Time_Patterns: [ '%Y%m%d' ]
        Date_Time_Keys: [ 'validity_ts' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L3_DSWx_HLS:
        # Pattern for parsing filenames such as:
        # * "OPERA_L3_DSWx-HLS_T22VEQ_20210905T143156Z_20220105T143156Z_L8_30_v0.1_B01_WTF.tif"
        # * "OPERA_L3_DSWx-HLS_T15SXR_20210907T163901Z_20220207T163901Z_S2A_30_v0.1_B09_CLOUD.tif"
        # This pattern groups the metadata information in the filename using named groups.
        #
        # Note: POSIX character class "[[:alnum:]]" is not supported in python's re, and so has been replaced with "[^\W_]" here.
        Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L3)_(?P<product_type>DSWx)-(?P<source>HLS)_(?P<tile_id>T[^\W_]{5})_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<sensor>S2A|S2B|S2C|S2D|L8|L9)_(?P<spacing>30)_(?P<product_version>v\d+[.]\d+))_(?P<band_index>B\d{2})_(?P<band_name>WTR|BWTR|CONF|DIAG|WTR-1|WTR-2|LAND|SHAD|CLOUD|DEM)[.](?P<ext>tif|tiff)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
            # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
            # For example, "20210211T163901":
            #   year: 2021
            #   month: 02 (February)
            #   day of month: 11 (the 11th)
            #   hour (24hr): 16
            #   minute: 39
            #   second: 01
            Date_Time_Patterns: ['%Y%m%dT%H%M%SZ']

            # Specify the metadata key to convert to a start and end time for the dataset times
            Date_Time_Keys: ['acquisition_ts', 'creation_ts']
            # Specify the metadata key to use as the dataset version.
            #  Note: this affects the data product index name
            Dataset_Version_Key: 'product_version'
        Dataset_Keys: {}

    L3_DSWx_S1:
      # Pattern for parsing filenames such as:
      # * "OPERA_L3_DSWx-S1_T18MVA_20200702T231843Z_20230317T190549Z_S1A_30_v0.1_B01_WTR.tif"
      # This pattern groups the metadata information in the filename using named groups.
      #
      # Note: POSIX character class "[[:alnum:]]" is not supported in python's re, and so has been replaced with "[^\W_]" here.
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L3)_(?P<product_type>DSWx)-(?P<source>S1)_(?P<tile_id>T[^\W_]{5})_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<sensor>S1A|S1B|S1C)_(?P<spacing>30)_(?P<product_version>v\d+[.]\d+))((_(?P<band_index>B\d{2})_(?P<band_name>WTR|BWTR|CONF|DIAG))|_BROWSE)?[.](?P<ext>tif|tiff|png|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
        # For example, "20210211T163901":
        #   year: 2021
        #   month: 02 (February)
        #   day of month: 11 (the 11th)
        #   hour (24hr): 16
        #   minute: 39
        #   second: 01
        Date_Time_Patterns: [ '%Y%m%dT%H%M%SZ' ]

        # Specify the metadata key to convert to a start and end time for the dataset times
        Date_Time_Keys: [ 'acquisition_ts', 'creation_ts' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L3_DISP_S1:
      # Pattern for parsing filenames such as:
      # * "OPERA_L3_DISP-S1_IW_F01234_VV_20190101T232711Z_20190906T232711Z_v0.1_20230101T100506Z.nc"
      # * "OPERA_L3_DISP-S1_IW_F01234_VV_20190101T232711Z_20190906T232711Z_v0.1_20230101T100506Z_BROWSE.png"
      # This pattern groups the metadata information in the filename using named groups.
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L3)_(?P<product_type>DISP)-(?P<source>S1)_(?P<mode>IW)_(?P<frame_id>F\d{5})_(?P<pol>VV|VH|HH|HV|VV\+VH|HH\+HV)_(?P<ref_datetime>\d{8}T\d{6}Z)_(?P<sec_datetime>\d{8}T\d{6}Z)_(?P<product_version>v\d+[.]\d+)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z))(_BROWSE)?[.](?P<ext>nc|png|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
        Date_Time_Patterns: [ '%Y%m%dT%H%M%SZ' ]

        # Specify the metadata key to convert to a start and end time for the dataset times
        Date_Time_Keys: [ 'ref_datetime', 'sec_datetime' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L3_DISP_S1_STATIC:
      # Pattern for parsing filenames such as:
      # * "OPERA_L3_DISP-S1-STATIC_F11115_20140403_S1A_v1.0_dem_warped_utm.tif"
      # * "OPERA_L3_DISP-S1-STATIC_F11115_20140403_S1A_v1.0_BROWSE.png"
      # This pattern groups the metadata information in the filename using named groups.
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L3)_(?P<product_type>DISP)-(?P<source>S1)-STATIC_(?P<frame_id>F\d{5})_(?P<validity_start_date>\d{8})_(?P<sensor>S1[A-C])_(?P<product_version>v\d+[.]\d+))(_(?P<band_name>dem_warped_utm|layover_shadow_mask|los_enu)|(_BROWSE))?[.](?P<ext>tif|png|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
        Date_Time_Patterns: [ '%Y%m%d' ]

        # Specify the metadata key to convert to a start and end time for the dataset times
        Date_Time_Keys: [ 'validity_start_date' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L2_CSLC_S1_COMPRESSED:
      # Pattern for parsing filenames such as:
      # * "OPERA_L2_COMPRESSED-CSLC-S1_F11114_T078-165495-IW3_20190906T000000Z_20190906T000000Z_20191108T000000Z_20230101T100506Z_VV_v1.0.h5"
      # This pattern groups the metadata information in the filename using named groups.
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L2)_(?P<product_type>COMPRESSED-CSLC)-(?P<source>S1)_(?P<disp_frame_id>F\d{5})_(?P<burst_id>\w{4}-\w{6}-\w{3})_(?P<ref_date_time>\d{8})T000000Z_(?P<first_date_time>\d{8})T000000Z_(?P<last_date_time>\d{8})T000000Z_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<pol>VV|VH|HH|HV|VV\+VH|HH\+HV)_(?P<product_version>v\d+[.]\d+))[.](?P<ext>h5)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
        Date_Time_Patterns: [ '%Y%m%d' ]

        # Specify the metadata key to convert to a start and end time for the dataset times
        Date_Time_Keys: [ 'first_date_time', 'last_date_time' ]
      Dataset_Keys: { }

    L3_DSWx_NI:
      # Pattern for parsing output image filenames, such as:
      # * "OPERA_L3_DSWx-NI_T11SLS_20110226T061749Z_20240329T181033Z_LSAR_30_v0.1_B01_WTR.tif"
      # * "OPERA_L3_DSWx-NI_T11SLT_20110226T061749Z_20240329T181033Z_LSAR_30_v0.1_BROWSE.png"
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L3)_(?P<product_type>DSWx)-(?P<source>NI)_(?P<tile_id>T[^\W_]{5})_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<sensor>LSAR)_(?P<spacing>30)_(?P<product_version>v\d+[.]\d+))((_(?P<band_index>B\d{2})_(?P<band_name>WTR|BWTR|CONF|DIAG))|_BROWSE)?[.](?P<ext>tif|tiff|png|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
        # For example, "20210211T163901":
        #   year: 2021
        #   month: 02 (February)
        #   day of month: 11 (the 11th)
        #   hour (24hr): 16
        #   minute: 39
        #   second: 01
        Date_Time_Patterns: [ '%Y%m%dT%H%M%SZ' ]

        # Specify the metadata key to convert to a start and end time for the dataset times
        Date_Time_Keys: [ 'acquisition_ts', 'creation_ts' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L3_DIST_S1:
      # Pattern for parsing output image filenames, such as:
      # * "OPERA_L3_DIST-S1_T15SXR_20210205T163901Z_20220101T140222Z_S1A_30_v0.1_DIST-GEN-STATUS.tif"
      # * "OPERA_L3_DIST-S1_T15SXR_20210205T163901Z_20220101T140222Z_S1A_30_v0.1_BROWSE.png"
      Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L3)_(?P<product_type>DIST(-ALERT)?)-(?P<source>S1)_(?P<tile_id>T[^\W_]{5})_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<sensor>S1[AC]?)_(?P<spacing>30)_(?P<product_version>v\d+[.]\d+))((_(?P<layer_name>DIST-GEN-STATUS|DIST-GEN-STATUS-ACQ|GEN-METRIC|DATE-FIRST|DATE-LATEST|N-DIST|N-OBS))|_BROWSE)?[.](?P<ext>tif|tiff|png|iso\.xml)$'
      Strip_File_Extension: !!bool true
      Extractor: extractor.FilenameRegexMetExtractor
      Configuration:
        # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
        # For example, "20210211T163901":
        #   year: 2021
        #   month: 02 (February)
        #   day of month: 11 (the 11th)
        #   hour (24hr): 16
        #   minute: 39
        #   second: 01
        Date_Time_Patterns: [ '%Y%m%dT%H%M%SZ' ]

        # Specify the metadata key to convert to a start and end time for the dataset times
        Date_Time_Keys: [ 'acquisition_ts', 'creation_ts' ]
        # Specify the metadata key to use as the dataset version.
        #  Note: this affects the data product index name
        Dataset_Version_Key: 'product_version'
      Dataset_Keys: { }

    L4_TROPO:
        # Pattern for parsing filenames
        #Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L4)_(?P<product_type>TROPO)_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<model>.+?)_(?P<spacing>\d+[.]\d+)_(?P<product_version>v\d+[.]\d+))?[.](?P<ext>nc|png)$'
        Pattern: !!python/regexp '(?P<id>(?P<project>OPERA)_(?P<level>L4)_(?P<product_type>TROPO)_(?P<acquisition_ts>(?P<acq_year>\d{4})(?P<acq_month>\d{2})(?P<acq_day>\d{2})T(?P<acq_hour>\d{2})(?P<acq_minute>\d{2})(?P<acq_second>\d{2})Z)_(?P<creation_ts>(?P<cre_year>\d{4})(?P<cre_month>\d{2})(?P<cre_day>\d{2})T(?P<cre_hour>\d{2})(?P<cre_minute>\d{2})(?P<cre_second>\d{2})Z)_(?P<model>.+?)_(?P<product_version>v\d+[.]\d+))?[.](?P<ext>nc|png)$'
        Strip_File_Extension: !!bool true
        Extractor: extractor.FilenameRegexMetExtractor
        Configuration:
          # Custom Pattern for dates like "<year><month><day>T<hour><minute><second>"
          # For example, "20210211T163901":
          #   year: 2021
          #   month: 02 (February)
          #   day of month: 11 (the 11th)
          #   hour (24hr): 16
          #   minute: 39
          #   second: 01
          Date_Time_Patterns: ['%Y%m%dT%H%M%SZ']
          # Specify the metadata key to convert to a start and end time for the dataset times
          Date_Time_Keys: [ 'acquisition_ts', 'creation_ts' ]
          Dataset_Version_Key: 'product_version'
        Dataset_Keys: { }

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# WARNING: ONLY MODIFY THE SETTINGS BELOW IF YOU KNOW WHAT YOU'RE DOING !!!!!!!!!!!!!!
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

# Settings to enable forceful ingest of PGE outputs (a.k.a disable no-clobber errors)
# These settings only take effect on those PGE jobs that produce datasets that get
# pushed to object storage (this should not include input product download jobs).
FORCE_INGEST:
    INGEST_STAGED: !!bool true
    slc_download: !!bool true
